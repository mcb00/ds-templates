{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for XGBoost\n",
    "\n",
    "This notebook collects some code for preparing a dataset for training in XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "In this example we'll work on the \n",
    "[Kagle Bluebook for Bulldozers](https://www.kaggle.com/competitions/bluebook-for-bulldozers/overview)\n",
    "competition, which asks us to build a regression model to predict the sale price of heavy equipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train.csv', parse_dates=['saledate']);\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare raw data for XGBoost\n",
    "\n",
    "All feature data must be numeric, and if the target is discrete, it must be encoded in 0,1,...K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode string features\n",
    "\n",
    "The simplest way to encode string variables is to map each unique string value to an integer;\n",
    "this is called *integer encoding*.\n",
    "\n",
    "We can easily accomplish this by using the [categorical data type in pandas](https://pandas.pydata.org/docs/user_guide/categorical.html).\n",
    "The category type is a bit like the factor type in R;\n",
    "pandas stores the underlying data as integers, and it keeps a mapping from the integers back to the original string values.\n",
    "XGBoost is able to access the numeric data underlying the categorical features for model training and prediction.\n",
    "This is a nice way to encode string features because it's easy to implement and it preserves the original category levels in the data frame.\n",
    "If you prefer to generate your own integer mappings, you can also do it with the scikit-learn\n",
    "[OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_cols_to_cat_cols(df, cols, as_codes=False):\n",
    "    out_df = df.copy()\n",
    "    for col in cols:\n",
    "        if as_codes:\n",
    "            out_df[col] = df[col].astype('category').cat.codes\n",
    "        else:\n",
    "            out_df[col] = df[col].astype('category')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the string columns to transform\n",
    "raw_string_cols = df.dtypes[df.dtypes == 'object'].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df = str_cols_to_cat_cols(df, raw_string_cols, as_codes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode datetime features\n",
    "\n",
    "While dates feel sort of numeric, they are not quite numbers, so we need to transform them  into numeric columns that XGBoosst can understand.\n",
    "A single date has many different attributes, e.g. days since epoch, year, quarter, month, day, day of year, day of week, is holiday, which can be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_features(df, datetime_columns, include_epoch=False, datetime_attributes=None):\n",
    "    out_df = df.copy()\n",
    "    datetime_attributes = datetime_attributes if datetime_attributes else []\n",
    "    epoch = pd.Timestamp(year=1970, month=1, day=1)\n",
    "    for col in datetime_columns:\n",
    "        if include_epoch:\n",
    "            out_df[f'{col}_days_since_epoch'] = (out_df[col] - epoch).dt.days\n",
    "        for datetime_attribute in datetime_attributes:\n",
    "            out_df[f'{col}_{datetime_attribute}'] = getattr(out_df[col].dt, datetime_attribute)\n",
    "    return out_df\n",
    "\n",
    "datetime_attributes = [\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'quarter',\n",
    "    'day_of_year',\n",
    "    'day_of_week',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the datetime columns\n",
    "datetime_cols = df.dtypes[df.dtypes == 'datetime64[ns]'].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proc_df = extract_datetime_features(proc_df, \n",
    "                                    datetime_cols, \n",
    "                                    include_epoch=True, \n",
    "                                    datetime_attributes=datetime_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Validation Set\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "n_valid = 12000\n",
    "train_df, valid_df = train_test_split(proc_df, test_size=n_valid, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Validation Set\n",
    "\n",
    "def train_test_split_temporal(df, datetime_column, n_valid):\n",
    "    idx_sort = np.argsort(df[datetime_column])\n",
    "    idx_train, idx_test = idx_sort[:-n_valid], idx_sort[-n_valid:]\n",
    "    return df.iloc[idx_train, :], df.iloc[idx_test, :]\n",
    "\n",
    "n_valid = 12000\n",
    "datetime_column = 'saledate' \n",
    "train_df, valid_df = train_test_split_temporal(proc_df, datetime_column, n_valid)\n",
    "train_df.shape, valid_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
