{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classification Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dbunch = datasets.load_breast_cancer(as_frame=True)\n",
    "df = dbunch.frame\n",
    "features = dbunch.feature_names \n",
    "target_names = dbunch.target_names \n",
    "target = 'target' \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_valid = 50 \n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=n_valid, random_state=42)\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with the  `train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "}\n",
    "num_boost_round = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(label=train_df[target], data=train_df[features])\n",
    "dvalid = xgb.DMatrix(label=valid_df[target], data=valid_df[features])\n",
    "model = xgb.train(params=params, dtrain=dtrain, num_boost_round=num_boost_round,\n",
    "                  evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                  verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "}\n",
    "num_boost_round = 50\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=num_boost_round, **params)\n",
    "clf.fit(train_df[features], train_df[target], \n",
    "        eval_set=[(train_df[features], train_df[target]), (valid_df[features], valid_df[target])], \n",
    "        verbose=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = valid_df[target]\n",
    "y_pred = clf.predict(valid_df[features])\n",
    "y_score = clf.predict_proba(valid_df[features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(metrics.log_loss, greater_is_better=False, needs_proba=True)\n",
    "permu_imp = permutation_importance(clf, valid_df[features], valid_df[target], \n",
    "                                   n_repeats=30, random_state=0, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_permutation = pd.Series(permu_imp['importances_mean'], index=features)\n",
    "importances_permutation.sort_values(ascending=True)[-10:].plot.barh()\n",
    "plt.title('Permutation Importance on Out-of-Sample Set')\n",
    "plt.xlabel('change in log likelihood');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch = datasets.fetch_covtype(as_frame=True)\n",
    "df = dbunch.frame\n",
    "features = dbunch.feature_names \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cover_Type'].value_counts().sort_index().plot.bar()\n",
    "plt.xlabel('cover type') \n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "target = 'encoded'\n",
    "enc = LabelEncoder()\n",
    "df[target] = enc.fit_transform(df['Cover_Type'])\n",
    "print(np.sort(df[target].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = 20000\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=n_valid, random_state=42)\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with the `train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'approx',\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': df[target].nunique()\n",
    "}\n",
    "num_boost_round = 10\n",
    "\n",
    "dtrain = xgb.DMatrix(label=train_df[target], data=train_df[features])\n",
    "dvalid = xgb.DMatrix(label=valid_df[target], data=valid_df[features])\n",
    "model = xgb.train(params=params, dtrain=dtrain, num_boost_round=num_boost_round,\n",
    "                  evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                  verbose_eval=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'approx',\n",
    "    'objective': 'multi:softprob',\n",
    "}\n",
    "num_boost_round = 10\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=num_boost_round, **params)\n",
    "clf.fit(train_df[features], train_df[target], \n",
    "        eval_set=[(train_df[features], train_df[target]), (valid_df[features], valid_df[target])], \n",
    "        verbose=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = valid_df[target]\n",
    "y_pred = clf.predict(valid_df[features])\n",
    "y_score = clf.predict_proba(valid_df[features])\n",
    "y_true.shape, y_pred.shape, y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_true, y_score, average='weighted', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(metrics.log_loss, greater_is_better=False, needs_proba=True)\n",
    "permu_imp = permutation_importance(clf, valid_df[features], valid_df[target], \n",
    "                                   n_repeats=30, random_state=0, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_permutation = pd.Series(permu_imp['importances_mean'], index=features)\n",
    "importances_permutation.sort_values(ascending=True)[-10:].plot.barh()\n",
    "plt.title('Permutation Importance on Out-of-Sample Set')\n",
    "plt.xlabel('change in multivariate log likelihood');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
